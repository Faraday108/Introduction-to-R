---
title: "R Syntax Examples"
author: "Nathan Young"
output: pdf_document
---

# R Nuts and Bolts
## Entering Input
We type expressions into the R prompt. 
The <- symbol is the assignment operator
```{r}
x <- 5 # Assignment of value to variable
print(x) # Explicit printing
x # auto-printing
y <- 10:20
```
When [1] is printed it indicates that x is a vector and that 5 is the first element
The : operator is used to create integer sequences

## R Objects
R has five basic classes of objects
- Character
- Numeric (real numbers)
- Integer
- Complex
- Logical (True/False)

The vector is the most basic object type, initialized with vector() function.  
A vector can only contain objects of the same class
A *list* is represented as a vector but can contain objects of different classes. 

## Numbers
Numbers are generally treated as numeric objects (such as double precision real numbers). Meaning, even if you see a '1' it is represented behind the scene as a numeric object like '1.00'. 
If you explicitly want an integer, use the L suffix. Entering '1' gives you a numeric object, while entering '1L' gives an integer object.   
Inf represents infinity. 
NaN represents an undefined value such as 0/0

## Attributes
R Objects can have many attributes (like metadata) to help describe the object. 
* Names, dimnames
* dimensions (matrices, arrays)
* class (integer, numeric)
* length
* other user-defined attributes/metadata

Attributes can be accessed using attributes() function. 

## Creating Vectors
The c() function can be used to create vectors of objects by concatenating things together. 
```{r}
x <- c(0.5, 0.6)       # numeric
x <- c(TRUE, FALSE)    # logical
x <- c(T, F)           # logical
x <- c("a", "b", "c")  # character
x <- 9:29              # integer
x <- c(1+0i, 2+4i)     # complex
x <- vector("numeric", length = 10) # initialize vector
```

## Mixing Objects
Sometimes we mix objects (on accident or on purpose).  
When different objects are mixed in a vector, they are *coerced* to be the same class. Sometimes this works the way you expect others, not. 

## Explicit Coercion
You can explicitly coerce between classes using the as.* function
```{r}
x <- 0:6
class(x)
as.numeric(x)
as.logical(x)
as.character(x)
```
Sometimes, R doesn't know what to do and will return NA. 

## Matrices 
Vectors with a *dimension* attribute. The dimension attribute is an integer vector of length 2
```{r}
m <- matrix (nrow = 2, ncol = 3)
dim(m)
attributes(m)
```
Matrics are constructed *column-wise*, so entries can be thought of starting in the "upper left" corner and running down the columns. 
```{r}
m <- matrix(1:6,nrow = 2, ncol = 3)
m
```
Can also be created directly from vectors by adding a dimension attribute. 
```{r}
m <- 1:10
m
dim(m) <- c(2,5)
m
```
Can be created with *column-binding* or *row-binding*
```{r}
x <- 1:3
y <- 10:13
cbind(x,y)
rbind(x,y)
```

## Lists
Special vectors that contain different elements of different classes.  
Can be explicitly created with the list() function. 
```{r}
x <- list(1, "a", TRUE, 1+4i)
x
```
Can also create an empty list of length with the vector() function.  
```{r}
x <- vector("list", length = 5)
```

## Factors
Used to represent categorical data that is unordered or ordered. Akin to integer vector where each integer has a label. Important for statical modeling and treated special in functions like lm() and glm().  
Using factors with labels is better than using integers because factors are self-describing. 
Factor with values "Male" and "Female" is better than variable with values 1 and 2. 
Create with factor() function
```{r}
x <- factor(c("yes", "yes", "no", "yes", "yes"))
x
table(x)
unclass(x)
```
Often, factors are automatically created when reading data with function like data.table().  
Order of levels can be set using levels argument to factor(). Often important in linear modeling with first level as baseline. 

## Missing Values
Denoted by NA or NaN for undefined mathematical operations
- is.na() is used to test for NA
- is.nan() is used to test for NaN
- NA values have a class also (integer NA, character NA, etc)
- A NaN value is also NA

```{r}
# create a vector with NAs in it
x <- c(1,2,NA,10,NaN,3)
# Return logical vector indicating which elements are NA
is.na(x)
# Return logical vector indicating which elements are NaN
is.nan(x)
```

## Data Frames
Used to store tabular data in R. Important in many statistical modeling. dplyr has optimized set of functions to work with data frames.  
Represented as special type of list where everyelement of the list has to have the same length. Each element can be thought of as a column and the length of each element of the list is the number of rows.  
Unlike matrices, can store different classes of objects in ach column.  
In addition to column names, DF have attribute called row.names to indicate informration about each row.  
Usually created by reading a dataset using read.table() or read.csv(). Can be created with data.frame() or converted from other objects.  
Can be converted to matrix with data.matrix(). 
```{r}
x <- data.frame(foo = 1:4, bar = c(TRUE, TRUE, FALSE, FALSE))
x
nrow(x)
ncol(x)
```

## Names
R objects can have names, helpful for readable code. 
```{r}
x <- 1:3
names(x)
names(x) <- c("New York", "Seattle", "Los Angeles")
x
names(x)

# Lists can also have names
x <- list("Los Angeles" = 1, Boston = 2, London = 3)
x
names(x)

# Matrices can have both row and column names
m <- matrix(1:4, nrow = 2, ncol = 2)
dimnames(m) <- list(c("a","b"),c("c","d"))
m
# Column names and row names can be specified separately
colnames(m) <- c("h","f")
rownames(m) <- c("x","z")
m
```
Note that for dataframes, there is a separate function for setting row names, the row.names(). DF do not have column names, just names. So you use the names() function. 

# Getting Data In and Out of R
## Reading and Writing Data
There are a few principal functions
- read.table, read.csv for reading tabluar data
- readLines for reading lines of a text file
- source, for reading in R code files (inverse of dump)
- dget, for reading in R code files (inverse of dput)
- load, for reading in saved workspaces
- unserialize, for reading simple R objects in binary form. 

Many packages exist for other datasets

Analogous functions for writing to files
- write.table for writing tabular to text files or connections
- writeLines, for writing character data line-by-line to file or conn
- dump, for dumping a textual representation of multiple R objects
- dput, for outputting a textual representation of an R object
- save, for saving an arbitrary number of R objects in binary format to a file
- serialize, for converting an R object into a binary format for outputting to a connection. 

## Reading Data Files with read.table()
Commonly used. Help file is worth reading. 
Arguments: 
- file, name of file, or connection
- header, logical indicating if file has a header
- sep, a string indicating how columns are separated
- colClasses, character vector indicating the class of each column
- nrows, number of rows. Default reads whole file
- comment.char, chacter string indicating comment character. 
- skip, number of lines to skip from beginning
- stringsAsFactors, should character variables be coded as factors? defaults to True. 

For small to moderate size, you can usually call read.table
```{r}
#data <- read.table("foo.txt")
```
- In this case, R will automatically skip lines that begin with #
- figure out how many rows there are and how much mem is needed. 
- figure out type of variable in each column. 

Telling R these things directly makes R faster and more efficient. 

## Reading in larger data sets with read.table
With larger data sets, make life easier and prevent R from choking by: 
- Read the help page for read.table
- Make a rough calculation of the memory required to store your dataset. If dataset is larger than RAM, stop. 
- set comment.char = "" if no commented lines in file
- Use colClasses argument. Specifing this can make it run **much** faster, often twice as fast. 

```{r}
#initial <- read.table("datatable.txt",nrows=100)
#classes <- sapply(initial,class)
#tabAll <- read.table("datatable.txt",colClasses=classes)
```
- set nrows. Doesn't make faster but helps with memory. 

Also useful to know about your system. 
- How much mem is available? 
- Can you close other applications? 
- Are there other users logged in? 
- What OS are you using? Some limit amount of memory. 

## Calculating Memory Requirements for R Objects
Because R stores all objects in physical memory, important to keep limits in mind. Especially when reading in a new dataset to R. BOTE are easy for it.  
Suppose data frame with 1,500,000 rows and 120 columns all of which are numeric. How much memory to store numeric data? 
1,500,000 x 120 x 8 bytes/numeric
= 1,440,000,000 bytes 
= 1,400,000,000 / 2^20 bytes/MB
= 1,373.29 MB
= 1.34 GB.

# Using the readr Package
Recently developed to deal with reading large flat files quickly, replacement for read.table() and read.csv(). Ananogous in readr are read_table() and read_csv().  
For the most part, can use these instead. 
```{r}
library(readr)
#teams <- read_csv("data/team_standings.csv")
#teams
```
By default, will open and read lint-by-line. Will also, read first few rows of table to figure out type of column. Can instead specify type of each column with col_types argument. Good idea in general.  
col_types accepts a compact representation. "cc" says first and second columns are characters.  
read_csv also reads compressed files automatically, no need to decompress.  
Can specify column type in detailed fashion using various col_* functions. 

# Using Textual and Binary Formats for Storing Data
Data can be stored in a variety of ways including strutured forms like CSV. Intermediate format that is textual, but not as simple as CSV.  
One can create a more descriptive representation of an R object by using the dput() or dump() functions; useful because resulting textual format is editable and recoverable in case of corruption. Preserve metadata (sacrificing readability) so user doesn't have to specify it again.  
Work much better with VC programs to track meaningful changes.  
Downsides include not space inefficiency and partial readibility. 

## Using dput() and dump()
One way to pass data around is deparsing the R object with dput() and reading it back in with dget().  
```{r}
# Create a data frame
y <- data.frame(a = 1, b = "a")
# Print 'dput' output to console
dput(y)
```
Notice that the dput() output is in the form of R code and that it preserves meta data like class, row names, and column names.  
Output can also be saved directly to a file
```{r}
# Send 'dput' output to a file
dput(y, file = "y.R")
# Read in 'dput' output from a file
new.y <-dget("y.R")
new.y
```
Multiple objects can be deparsed at once using the dump function and read back in using source
```{r}
x <- "foo"
y <- data.frame(a = 1L, b = "a")
dump(c("x","y"),file = "data.R")
rm(x,y)
# Inverse of dump is source
source("data.R")
str(y)
x
```
# Binary Formats
The complement to the textual format is the binary format. Use for efficiency purposes or if no useful way to represent data with text. Also, can lose precision on numeric data when converting to and from textual format.  
Convert R object to binary: save(), save.image(), serialize().  
Individual objects with save() function
```{r}
a <- data.frame(x = rnorm(100), y = runif(100))
b <- c(3, 4.4, 1/3)
# Save 'a' and 'b' to a file
save(a, b, file = "mydata.rda")
# Load 'a' and 'b' into workspace
load("mydata.rda")
```
Save lots of objects with save.image()
```{r}
# Save everything
save.image(file = "mydata.RData")
# Load all objects in this file
load("mydata.RData")
```
Example used .rda for save and .RData for save.image. Can use other formats but these are common and accessible.  
serialize() converts individual R objects to binary format that can be communicated across an arbitrary connection (file or network).  
Coded as a raw vector in hexadecimal. 
```{r}
x <- list(1, 2, 3)
serialize(x,NULL)
```
Can be sent to a file, but better of using save for that.  
Benefit to serialize: perfectly represent R object in an exportable format, without losing precision or metadata. 

# Interfaces to the Outside World
Data are read in using *connection* interfaces. Connections can be made to files or more exotic things. 
- file, opens connection to file
- gzfile, opens connection to file compressed with gzip
- bzfile, opens connection to file compressed with bzip2
- url, opens connection to webpage. 

Think of connections as translator that lets you talk to objects outside of R.  
## File Connections
Connections to file using file()  
```{r}
str(file)
```
Arguments: 

- description, name of file
- open, mode to open file 
  + 'r' read mode
  + 'w' write mote (and initialize new file)
  + 'a' appending
  + 'rb', 'wb', 'ab' readin writing appending in binary

Most of connection is dealt with in background and we don't deal with it. 
```{r}
# Create connection to 'foo.txt'
con <- file("foo.txt")
# Open connetion in read mode
open(con, "r")
# Read from connection 
data <- read.csv(con)
# Close connection
close(con)

# this is all the same as: 
data <- read.csv("foo.txt")
```
In the background, read.csv() opens a connection, reads, and closes the connection. 

# Reading Lines of a Text File
Lines of text file can be read line by line with readLines(). Useful for unstructured and nonstandard data.  
```{r}
# Open connection to gz-compressed file
# con <- gzfile("words.gz")
# x <- readLines(con,10)
# x
```
For more structured text like CSV, other functions like read.csv() and read.table() exits.  
In above, gzfile() is used to create connections to compressed data with gzip algorithm. Lets you not unzip files.  
Complementary function writeLines() to write character vector element wise to each line. 

## Reading from a URL Connection
readLines() is useful for reading in lines of webpages that are text files stored on a server. url() function navigates communication between computer and web server. 
```{r}
# Open a url connection for reading
con <- url("https://www.jhu.edu","r")

# Read the webpage
x <- readLines(con)

# Print first few lines
head(x)
```
Reading a simple page is sometimes useful, more commonly used to read data stored on web servers.  
Using URL connections can be useful for producing a reproducible analysis, because code documents where the data cam from and how it was obtained. Preferable to opening a webpage and downloading dataset by hand. If server is changed, can break code. 

# Subsetting R Objects
Three operators to extract subsets of R Objects

* The "[]" operator always returns an object of the same class as the original, can be used to select multiple elements of object
* [[]] operator is used to extract elements of a list or data frame. Used to extract single element and class of returned object will not necessarily be a list or data frame. 
* $ operator is used to extract elements of a list by literal name. 

## Subsetting a Vector
Vectors are basic objects and are subsetted using the [] operator.  
```{r}
x <- c("a", "b", "c", "c", "d", "a")
x[1]
x[2]
# Can be used to extract multiple elements by passing an inteer sequence. 
x[1:4]
# Sequence doesn't need to be in order
x[c(1, 3, 4)]
# Can also pass logical sequence. For example, elements of x that come alphabetically after letter a
u <- x > "a"
x[u]
# More compactly:
x[x > "a"]
```

# Subsetting a Matrix
Subsetted in usual way with (*i*, *j*) indices. Row x column
```{r}
x <- matrix(1:6, 2, 3)
x
# access elements using indices
x[1,2]
x[2,1]
# Missing index indicates entire row/column
x[1,]
x[,2]
```
### Dropping Matrix Dimensions
By default, when you index a single element a vector length 1 is returned. Can turn this off. 
```[r}
x <- matrix(1:6, 2, 3)
x[1,2]
x[1, 2, drop = FALSE]
# Similar use to keep matrix dimensions for extracting entire row. 
x[1,]
x[1, , drop = FALSE]
```
**Be careful of R's automatic dropping of dimensions**

## Subsetting Lists
```{r}
x <- list(foo - 1:4, bar = 0.6)
x
## The [[]] operator can be used to extract a single element from a list
x[[1]]
## Can also use named indices or $ operator to extract by name
x[["bar"]]
x$bar
# Don't need quotes on $ operator. 
# [[ can be used with computed indices, $ operator can only be used with names
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
name <- "foo"

# Computed index for "foo"
x[[name]]
# element name doesn't exist! 
x$name
```

## Subsetting Nested Elements of a List
The [[]] operator can take an integer sequence
```{r}
x <- list(a = list(10, 12, 14), b = c(3.14, 2.81))
# Get 3rd element of the first element
x[[c(1,3)]]
# Alternative
x[[1]][[3]]
# first element of second element
x[[c(2,1)]]
```

## Extracting Multiple Elements of a List
The [] operator can extract multiples
```{r}
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
x[c(1,3)]
```
Note that x[c(1,3)] is not the same as x[[c(1,3)]]! 

# Dates and Times
R has a special representation for date and time with. Date class for dates and POSIXct or POSIXlt for times. Date is stored as number of days since 1970-01-01 while time is number osf seconds since 1970-01-01. 

## Dates in R
Dates are represented by Date class and can be coerced from a character string with as.Date(). 
```{r}
# Coerce a date object from character
x <- as.Date("1970-01-01")
x
# You can see internal representation of Date object by using the unclass() function. 
unclass(x)
unclass(as.Date("1970-01-02"))
```

## Times in R
Times are represented by POSIXct or POSIXlt. 
POSIXct is just a large integer underneath and useful for storing in data frame. 
POSIXlt is a list underneath and stores extra info like day of week, year, month, day of month. Useful if you need extra info. 

Generic Functions

- weekdays: gives day of week
- months: gives the month dame
- quarters: gives the quarter number "Q1" etc. 

Times can be coerced from character string using as.POSIXlt or as.POSIXct
```{r}
x <- Sys.time()
x
class(x)
# POSIXlt has useful metadata
p <- as.POSIXlt(x)
names(unclass(p))
p$wday

# can also use POSIXct format
x <- Sys.time() 
x # already in POSIXct format
unclass(x) # Internal representation
x$sec #Won't work! 
p <- as.POSIXlt(x)
p$sec

# strptime() for dates in different format. Takes character vector and converts them to POSIXlt object. 
datestring <- c("January 1, 2012 10:40", "December 9, 2011 9:10")
x <- strptime(datestring, "%B %d, %Y %H:%M")
x
class(x)
```
The % symbols are for formatting strings for dates and times. Probably not worth memorizing. Check ?strptime for details. 

## Operations on Dates and Times
Can use +, - and comparisions (==, <=, etc)

```{r}
x <- as.Date("2012-01-01")
y <- strptime("9 Jan 2011 11:34:21", "%d %b %Y %H:%M:%S")
x - y
x <- as.POSIXlt(x)
x - y
```
A nice feature of this class is it keeps track of leap years, daylight savings, time zones. 
```{r}
x <- as.Date("2012-03-01")
y <- as.Date("2012-02-28")
x - y
# Timezone
x <- as.POSIXct("2012-10-25 01:00:00")
y <- as.POSIXct("2012-10-25 06:00:00", tz="GMT")
y - x
```

# Managing Data Frames with the dplyr package
## Data Frames
DF are a key structure. Basic structure is one observation per row and each column represents a variable, measure, feature, or characteristic. Extra formats downloadable from CRAN that give better implementation for things like large datasets. 
Tools for dealing with them include subset(), [], and $ to extract subsets. Other operations with base R like filtering, reordering, and collapsing can be tedious. dplyr helps mitigate and optimize these challenges. 

## The dplyr Package
Doesn't introduce anything new, but it *greatly* simplifies existing functionality. It provides a "grammar" for data manipulation and operating on data frames. Helps communicate what you are doing to a data frame. Also, dplyr is very fast. 

## dplyr Grammar
key "verbs":

* select: return a subset of the columns of a data frame, using flexible notation
* filter: extract a subset of rows from data frame based on logical conditions
* arrange: reorder rows of a data frame
* rename: rename variables in data frame
* mutate: add new variables/columns or transform existing variables. 
* summarize/summarise: generate summary table of statistics of different variables in data frame, possibly within strata. 
* %>%: the "pipe" operator is used to connect multiple verb actions into a pipeline. 

dplyr package also includes a number of data types. 

### Common dplyr function properties

1. The first argument is a data frame
2. The subsequent arguments describe what to do with the data frame, and you can refer to columns in the data frame directly without the $ operator. 
3. The return result of the function is a new data frame. 
4. Data frames must be properly formatted and annotated to be useful. Data should be tidy: one observation per row, each column with a feature or characteristic of observation. 

## Installing dplyr package
Can be installed from CRAN or GitHub uisng devtools pacakage and install_github() fuction. GitHub usually has latest updates of function.  
To install from CRAN, run
```{r}
install.packages("dplyr")
```
To install from GitHub use
```{r}
install_github("hadley/dplyr")
```
Remember to load into R session with library()!
```{r}
library(dplyr)
```
If R gives warnings about functions with the same name, ignore for now.

## select()
Examples in this section will use dataset available from textbook's website. Download an unzip then load using readRDS()
```{r}
chicago <- readRDS("chicago.rds")
# Basic characteristics
dim(chicago)
str(chicago)
```
select() function to select columns to focus on. You'll often have large dataset but any given analysis will use subset. 
Suppose we want first 3 columns. Can use numeric index or column names directly. 
```{r}
names(chicago)[1:3]
subset <- select(chicago,city:dptp)
head(subset)
# Note that the : normally cannot be used with names of strings, but inside select() can specify range of var names. 
# Can also omit variables using negative sign. 
select(chicago, -(city:dptp))
# Indicates every variable except city through dptp. Equivalent code:
i <- match("city",names(chicago))
j <- match("dptp", names(chicago))
head(chicago[,-(i:j)]
```
Select also lets special syntax for patterns
```{r}
# keep var ending with "2"
subset <- select(chicago,ends_with("2"))
str(subset)
# or keeping every variable that starts with "d"
subset <- select(chicago, starts_with("d))
str(subset)
```
You can also use general regex. 

## filter()
Extract subset rows. Similar to subset() but faster. 
Extract rows with PM2.5 greater than 30
```{r}
chic.f <- filter(chicago,pm25tmean2 > 30)
str(chic.f)
summary(chic.f$pm25tmean2)

# Can extract arbitrarily complex logical sequence inside of filter()

chic.f <- filter(chicago, pm25tmean > 30 & tmpd > 80)
select(chic.f, date, tmpd, pm25tmean2)
```

## arrange()
Used to reorder rows according to one of the variables/columns. Reordering, while preserving order of other columns, is a pain in R. arrange() simplifies the process. 
```{r}
chicago <- arrange(chicago, date) #starts at earliest, ends at oldest
head(select(chicago, date, pm25tmean2), 3)
tail(select(chicago, date, pm25tmean2), 3)

# Columns can be arranged in descending order too using desc() operator
chicago <- arrange(chicago, desc(date))
head(select(chicago, date, pm25tmean2),3)
tail(select(chicago, date, pm25tmean2),3)
```

## rename()
Renaming a variable in R is surprisingly hard to do! rename() makes it easier. 
```{r}
head(chicago[, 1:5],3) # names of first 5 variables
# dptp represents dew point temp
# pm25tmean2 provides PM2.5 data
# The given names are obscure and can be renamed
chicago <- rename(chicago, dewpoint = dptp, pm25 = pm25tmean2)
head(chicago[,1:5],3)
```

## mutate()
Compute transformations of variables, such as deriving new variables from existing. 
For example, can 'detrend' data by subtracting a mean to see how it differs from average rather than absolute level. 
```{r}
chicago <- mutate(chicaago, pm25detrend = pm25 - mean(pm25, na.rm = TRUE))
head(chicago)
```
transmute() does the same as mutate but then *drops all non-transformed variables*
```{r}
head(transmute(chicago,
  pm10detrend = pm10tmean2 - mean(pm10tmean2, na.rm = TRUE),
  o3detrend = o3tmean2 - mean(o3tmean2, na.rm = TRUE)))
```

## group_by()
Creates summary statistics from the data frame within strata defined by a variable. For example, can compute average annual level of PM2.5. Stratum is the year, derived from date. 
Standard operation is split data frame into separate pieces defined by variable or group of variables with group_by(), then apply summary function.
```{r}
chicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900) # year variable
years <- group_by(chicago, year) # create separate data frame that splits original DF by year. 
# Finally, compute summary statistics
summarize(years), pm25 = mean(pm25, na.rm = TRUE),
  o3 = max(o3tmean2,na.rm = TRUE),
  no2 = median(no2tmean2,na.rm = TRUE),
  .groups = "drop")
 
```
summarize() returns a dataframe with year as first column, then annual averages of pm25, o2, and no2. 
As a more complicated example, might want to know average levels of ozone and nitrogen dioxide within quintiles of pm25. A regression model would be slicker, but we can do quickly with group_by() and summarize(). 

```{r}
qq <- quantile(chicago$pm25,seq(0,1,0.2),na.rm = TRUE)
chicago <- utate(chicago, pm25.quint = cut(pm25,qq))
# Now we can group the data frame by the pm.25 quint variable. 
quint <- group_by(chicago, pm25.quint)
# Finally, compute mean within quintiles. 
summarize(quint, o3 = mean(o3tmean2, na.rm = TRUE),
  no2 = mean(no2tmean2, na.rm = TRUE),
  .groups = "drop")
```

From the table above, there isn't a strong relationship between pm25 and o3, but a positive correlation between pm25 and no2. More sophisticated stat modeling can give precise answers to these questions, but this application can get you most of the way there. 

## %>%
The pipeline operator is handy for stringing together multiple functions in a sequence of operations. Above, we had to nest the functions when applying multiple. The pipeline operator lets you string operations left to right instead of nesting. In the last section we had to: 

1. create a new variable pm25.quint
2. split the data frame by that new variable
3. compute the mean of o3 and no2 in the sub-groups defined by pm25.quint

That can be done with the following sequene: 
```{r}
mutate(chicago, pm25.quint = cut(pm25,qq)) %>%
  group_by(pm25.quint) %>%
  summarize(o3 = mean(o3tmean2, na.rm = TRUE),
    no2 = mean(no2tmean2, na.rm = TRUE),
    .groups = "drop")
```
This helps us not create a set of temporary variables along the way or massive nested sequences. The first argument of a pipeline is taken to be the output of the previous element in the pipeline. 
Another example is average pollutant level by month. 
```{r}
mutate(chicago, month = as.POSIXlt(date)$mon + 1) %>%
  group_by(month) %>%
  summarize(pm25 = mean(pm25, na.rm = TRUE),
    o3 = max(o3tmean2, na.rm = TRUE),
    no2 = median(no2tmean2, na.rm = TRUE),
    .groups = "drop)
```

## Summary
the dplyr package provides a concise set of operations for managing data frames. 
Additonal benefits: 

* can work with other data frame "backends" such as SQL databases. There is an SQL interface for relational databases via the DBI package
* can be integrated with the data.table package for large fast tables.

# Control Structures
Control flow of execution, put "logic" into code. 
Commonly used strutures: 

* if and else: testing a condition and acting on it
* for: execute a loop a fixed number of times
* while: execute a loop while a condition is true
* repeat: execute an infinite loop (must break to stop)
* break: break execution of loop
* next: skip an interation

Not really used in interactive sessions, but when writing functions and long expressions. 

## if-else
Common conditional
if(<condition>) {
  do something
}
else {
  do something else
}
rest of code
Does nothing if condition is false, if you want an action when false, use else. 
Can have series of tests: 
if(<condition1>) {
  do something
  }
else if (<condition2>) {
  do something different
  }
else {
  do something different
}

